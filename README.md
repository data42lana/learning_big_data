## Big Data Analysis with PySpark - WDI
---
A Jupyter notebook with an example of big data analysis using the **PySpark SQL** module.
### Overview:
---
The objective of the project is to learn tools of the PySpark SQL module for working with big data on an example of analysis of World Development Indicators. It used DataFrames and its methods, built-in functions, window functions, and converting SQL queries to DataFrame. Suitable for those who want to see how these tools work in practice.
### Setup:
---
The Jupyter notebook was created in Google Colaboratory, and the data was stored on Google Drive, so it's easier to open and run it there, but first replace or recreate all the data paths for loading and saving. 
### Versions of packages used:
---
python 3.7.10, Spark 3.0.1, Hadoop 2.7, Java8 JDK, findspark 1.4.2
### Data: 
---
For the analysis, we took data from [World Development Indicators, The World Bank](https://datacatalog.worldbank.org/dataset/world-development-indicators): zip archive with CSV files from the "Data & Resources" tab. We used only the files "WDIData", "WDICountry" and "WDISeries".
### How can you help:
If you find any bugs, issues, or have any questions or recommendations for improvement this project, please write about it.
